{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa0FJhCaS7wD6mTy5+pIx2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashSeervi2003/PW_Assignment/blob/main/MachineLearningAssignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is a parameter?**\n",
        "\n",
        "A parameter in Machine Learning is a value learned by the model during training that determines the relationship between input features and the output predictions, such as weights and biases in a model."
      ],
      "metadata": {
        "id": "tftqYTpQbBXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What is correlation? What does negative correlation mean?**\n",
        "\n",
        "Correlation measures the strength and direction of the linear relationship between two variables, ranging from -1 to 1. A positive value indicates a direct relationship, while a negative value indicates an inverse relationship.\n",
        "\n",
        "\n",
        "Negative correlation means that as one variable increases, the other decreases. For example, temperature and heater usage typically have a negative correlation."
      ],
      "metadata": {
        "id": "zTY2zSpebO-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Define Machine Learning. What are the main components in Machine Learning?**\n",
        "\n",
        "Machine Learning is a branch of artificial intelligence where computers learn patterns from data to make decisions or predictions without being explicitly programmed.\n",
        "\n",
        "Main Components in Machine Learning:\n",
        "\n",
        "* Data: The input used to train and test the model.\n",
        "* Model: The mathematical representation that maps inputs to outputs.\n",
        "* Algorithm: The procedure used to train the model by adjusting its parameters.\n",
        "* Evaluation: Methods to measure the model's performance, such as accuracy or loss."
      ],
      "metadata": {
        "id": "0g57fV1sbexC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. How does loss value help in determining whether the model is good or not?**\n",
        "\n",
        "The loss value quantifies the error between the model's predictions and the actual target values. It helps determine whether the model is good by indicating how well the model fits the data:\n",
        "\n",
        "Lower Loss Value: A smaller loss value indicates that the model's predictions are closer to the actual values, suggesting better performance.\n",
        "\n",
        "Higher Loss Value: A larger loss value means the predictions are far from the actual values, implying poor performance.\n",
        "\n",
        "By minimizing the loss value during training, the model improves its accuracy and generalization to unseen data."
      ],
      "metadata": {
        "id": "4Crap00ebyyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What are continuous and categorical variables?**\n",
        "\n",
        "**Continuous Variables:**\n",
        "\n",
        "Continuous variables are numeric variables that can take any value within a range. They have an infinite number of possible values and are measurable.\n",
        "Examples: Age, height, weight, temperature.\n",
        "\n",
        "**Categorical Variables:**\n",
        "\n",
        "Categorical variables represent data that can be divided into distinct categories or groups. They are qualitative and often take a limited number of values.\n",
        "Examples: Gender (male/female), color (red/blue/green), city names.\n",
        "\n",
        "In machine learning, continuous variables are often scaled, while categorical variables are encoded to be used in models."
      ],
      "metadata": {
        "id": "d2SktWYWcBV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "\n",
        "**Handling Categorical Variables in Machine Learning:**\n",
        "\n",
        "Categorical variables need to be converted into numerical representations for machine learning models.\n",
        "\n",
        "**Common Techniques:**\n",
        "\n",
        "**Label Encoding:** Assigns a unique integer to each category. Useful for ordinal data (e.g., [\"Low\", \"Medium\", \"High\"] → [0, 1, 2]).\n",
        "\n",
        "**One-Hot Encoding:** Creates a binary column for each category. Suitable for nominal data (e.g., [\"Red\", \"Blue\", \"Green\"] → 3 binary columns)."
      ],
      "metadata": {
        "id": "ecdo5MqXcV2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What do you mean by training and testing a dataset?**\n",
        "\n",
        "\n",
        "**Training a Dataset:**\n",
        "\n",
        "Training a dataset refers to using a portion of the data to teach the machine learning model how to make predictions. The model learns patterns and relationships between input features and the target variable.\n",
        "\n",
        "**Testing a Dataset:**\n",
        "\n",
        "Testing a dataset refers to evaluating the trained model's performance on a separate set of data (the test set) that was not used during training. This helps assess how well the model generalizes to unseen data."
      ],
      "metadata": {
        "id": "n6dLvXhQdPmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What is sklearn.preprocessing?**\n",
        "\n",
        "sklearn.preprocessing is a module in Scikit-learn that provides various tools to preprocess data before feeding it into a machine learning model. It includes techniques for scaling, normalizing, encoding categorical variables, and transforming data into a suitable format for modeling."
      ],
      "metadata": {
        "id": "STct2TzEdfcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is a Test set?**\n",
        "\n",
        "A Test set is a subset of the dataset that is used to evaluate the performance of a machine learning model after it has been trained. The test set is separate from the training data and contains unseen data, ensuring that the model's evaluation reflects how well it generalizes to new, real-world data."
      ],
      "metadata": {
        "id": "65ri6cqsds4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. How do we split data for model fitting (training and testing) in Python?**\n",
        "**How do you approach a Machine Learning problem?**\n",
        "\n",
        "**How to Split Data for Model Fitting (Training and Testing) in Python:**\n",
        "\n",
        "To split the dataset into training and testing sets in Python, use the train_test_split() function from Scikit-learn:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X: Features (independent variables).\n",
        "\n",
        "y: Target variable (dependent variable).\n",
        "\n",
        "test_size: The proportion of the dataset used for testing (e.g., 0.2 means 20% for testing).\n",
        "\n",
        "random_state: Ensures reproducibility by setting a seed for the split.\n",
        "\n",
        "**How Do You Approach a Machine Learning Problem?**\n",
        "\n",
        "1. Define the Problem:\n",
        "Understand the type of problem (e.g., classification, regression) and its objective.\n",
        "\n",
        "2. Prepare the Data:\n",
        "Clean the data, handle missing values, and encode categorical variables.\n",
        "\n",
        "3. Split the Data:\n",
        "Use train_test_split() to divide data into training and testing sets.\n",
        "\n",
        "4. Choose a Model:\n",
        "Select an appropriate model (e.g., Logistic Regression, Random Forest).\n",
        "\n",
        "5. Train the Model:\n",
        "Fit the model to the training data.\n",
        "\n",
        "6. Evaluate the Model:\n",
        "Use the test data to evaluate model performance using relevant metrics (e.g., accuracy, RMSE).\n",
        "\n",
        "7. Optimize:\n",
        "Tune hyperparameters using methods like GridSearchCV or RandomizedSearchCV to improve model performance.\n"
      ],
      "metadata": {
        "id": "HHEt6Gqsd4wK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Why do we have to perform EDA before fitting a model to the data?**\n",
        "\n",
        "Exploratory Data Analysis (EDA) is crucial before fitting a model because it helps to:\n",
        "\n",
        "1. **Understand the Data**: EDA allows you to identify patterns, trends, and anomalies in the dataset, such as missing values, outliers, and relationships between variables.\n",
        "\n",
        "2. **Feature Selection and Engineering**: It helps in selecting relevant features for the model and transforming or creating new features to improve model performance."
      ],
      "metadata": {
        "id": "w_Q3rdfGfK8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. What is correlation?**\n",
        "\n",
        "\n",
        "Correlation is a statistical measure that indicates the strength and direction of the relationship between two variables. It ranges from -1 to 1:\n",
        "\n",
        "* Positive correlation (closer to 1) means as one variable increases, the other also increases.\n",
        "* Negative correlation (closer to -1) means as one variable increases, the other decreases.\n",
        "* Zero correlation means no linear relationship between the variables."
      ],
      "metadata": {
        "id": "7XBP8Pe8fbjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. What does negative correlation mean?**\n",
        "\n",
        "Negative correlation means that as one variable increases, the other decreases. In other words, the two variables move in opposite directions.\n",
        "\n",
        "**For example:**\n",
        "\n",
        "* As the temperature decreases, the demand for heating might increase, indicating a negative correlation between temperature and heating demand.\n",
        "\n",
        "The correlation value for negative correlation ranges between 0 and -1, where -1 indicates a perfect negative correlation."
      ],
      "metadata": {
        "id": "WjLusgWVfpcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. How can you find correlation between variables in Python?**\n",
        "\n",
        "To find the correlation between variables in Python, you can use the corr() method provided by Pandas. It computes the pairwise correlation between numerical columns in a DataFrame.\n",
        "\n",
        "**Example:**"
      ],
      "metadata": {
        "id": "R8rwAVrtf1O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'X': [1, 2, 3, 4, 5], 'Y': [5, 4, 3, 2, 1], 'Z': [1, 3, 5, 7, 9]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Find correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5KChSs9gDtn",
        "outputId": "d07eef7c-fdcf-4d03-ad4c-c20f09770347"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X    Y    Z\n",
            "X  1.0 -1.0  1.0\n",
            "Y -1.0  1.0 -1.0\n",
            "Z  1.0 -1.0  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will output a correlation matrix showing the correlation values between each pair of variables.\n",
        "\n",
        "* df.corr() computes the Pearson correlation by default, which measures linear relationships. For other types of correlation (e.g., Spearman), you can specify the method: df.corr(method='spearman')."
      ],
      "metadata": {
        "id": "xSdxpRpggGta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. What is causation? Explain difference between correlation and causation with an example**\n",
        "\n",
        "Causation refers to a cause-and-effect relationship where one variable directly influences or causes a change in another variable.\n",
        "\n",
        "**Difference Between Correlation and Causation:**\n",
        "* Correlation indicates a statistical relationship between two variables but does not prove that one causes the other.\n",
        "* Causation means that changes in one variable directly result in changes in another.\n",
        "\n",
        "**Example:**\n",
        "* Correlation: There is a correlation between the number of people carrying umbrellas and the amount of rainfall. However, carrying an umbrella does not cause rainfall, they are correlated due to the weather.\n",
        "* Causation: Smoking causes lung cancer. Here, smoking directly leads to the development of cancer, establishing causation."
      ],
      "metadata": {
        "id": "8CLZqJQNgMkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "\n",
        "An Optimizer in machine learning is an algorithm used to minimize or maximize an objective function, usually the loss function, by updating the model's parameters (weights and biases). The goal is to find the optimal values for these parameters that lead to the best model performance.\n",
        "\n",
        "**Types of Optimizers:**\n",
        "\n",
        "1. **Gradient Descent:**\n",
        "\n",
        " *  **Explanation:** It updates model parameters by moving them in the direction opposite to the gradient of the loss function. The step size is controlled by a learning rate.\n",
        " *  **Example:** For a quadratic loss function, gradient descent will iteratively adjust weights to reduce the error.\n",
        "\n",
        "2. **Stochastic Gradient Descent (SGD):**\n",
        "\n",
        " *  **Explanation:** It updates parameters using a single random data point at each iteration, instead of the entire dataset. This introduces more variability but can speed up learning.\n",
        " *  **Example:** For a large dataset, instead of using all data points, SGD uses one at a time to update the weights.\n",
        "\n",
        "3. **Momentum:**\n",
        "\n",
        " *  **Explanation:** It improves gradient descent by adding a \"momentum\" term, which helps accelerate gradients in the correct direction and dampens oscillations.\n",
        "\n",
        " *  **Example:** In training deep neural networks, momentum helps the model converge faster than vanilla gradient descent.\n",
        "\n",
        "4. **Adam (Adaptive Moment Estimation):**\n",
        "\n",
        " *  **Explanation:** It combines the advantages of both AdaGrad and RMSProp by using both the first and second moments of gradients to adjust the learning rate dynamically for each parameter.\n",
        " *  **Example:** Adam is widely used in deep learning tasks, as it adapts the learning rate and converges faster in practice.\n",
        "These optimizers help in minimizing the loss function by adjusting the model parameters iteratively to improve the model's performance."
      ],
      "metadata": {
        "id": "KL4s02uVgolp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is sklearn.linear_model ?**\n",
        "\n",
        "\n",
        "sklearn.linear_model is a module in Scikit-learn that provides linear models for regression and classification tasks. These models assume a linear relationship between the input features and the target variable."
      ],
      "metadata": {
        "id": "9g0cRO1NhqoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. What does model.fit() do? What arguments must be given?**\n",
        "\n",
        "The model.fit() method is used to train a machine learning model on the given dataset. It adjusts the model's parameters (such as weights in linear models) to minimize the loss function based on the input data.\n",
        "\n",
        "**Arguments:**\n",
        "* X (features): The input data (independent variables) used for training.\n",
        "* y (target): The target values (dependent variable) corresponding to the input data.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "This trains the model using the training data (X_train) and their corresponding labels (y_train)."
      ],
      "metadata": {
        "id": "2CFv8Wzwh0Rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. What does model.predict() do? What arguments must be given?**\n",
        "\n",
        "The model.predict() method is used to make predictions on new, unseen data after the model has been trained using the fit() method.\n",
        "\n",
        "**Arguments:**\n",
        "* X (features): The input data (independent variables) for which predictions are to be made.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "Here, model.predict() will generate predictions based on the features in X_test (test set), which can then be compared to the actual target values for evaluation."
      ],
      "metadata": {
        "id": "uK1paHgYiGwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. What are continuous and categorical variables?**\n",
        "\n",
        "**Continuous Variables** are numerical variables that can take an infinite number of values within a given range. These variables are measurable and can represent quantities that are on a continuous scale.\n",
        "\n",
        "* **Example:** Temperature (e.g., 22.5°C, 23.1°C), Height (e.g., 5.5 feet, 6.1 feet), Salary.\n",
        "\n",
        "**Categorical Variables** are variables that represent categories or labels. These variables have a fixed number of distinct categories or levels and are often non-numerical.\n",
        "\n",
        "* **Example:** Gender (e.g., Male, Female), Color (e.g., Red, Blue, Green), Marital Status (e.g., Single, Married)."
      ],
      "metadata": {
        "id": "DsS8kgOXiTHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. What is feature scaling? How does it help in Machine Learning?**\n",
        "\n",
        "Feature Scaling is the process of standardizing or normalizing the range of independent variables (features) in a dataset. It ensures that all features contribute equally to the model by bringing them to a similar scale.\n",
        "\n",
        "This helps improve the performance of machine learning algorithms by preventing features with larger ranges from dominating the model. It is especially important for distance-based algorithms like KNN and SVM."
      ],
      "metadata": {
        "id": "jDfvKJKbinKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. How do we perform scaling in Python?**\n",
        "\n",
        "In Python, feature scaling can be performed using StandardScaler for standardization and MinMaxScaler for normalization from sklearn.preprocessing. These scale features to have a mean of 0 and unit variance, or a range of 0 to 1, respectively."
      ],
      "metadata": {
        "id": "7PNolse_i5_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. What is sklearn.preprocessing?**\n",
        "\n",
        "sklearn.preprocessing is a module in Scikit-learn that provides various tools to preprocess data before feeding it into a machine learning model. It includes techniques for scaling, normalizing, encoding categorical variables, and transforming data into a suitable format for modeling."
      ],
      "metadata": {
        "id": "Wq9N0aSqjLci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24. How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "\n",
        "\n",
        "To split the dataset into training and testing sets in Python, use the train_test_split() function from Scikit-learn:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X: Features (independent variables).\n",
        "\n",
        "y: Target variable (dependent variable).\n",
        "\n",
        "test_size: The proportion of the dataset used for testing (e.g., 0.2 means 20% for testing).\n",
        "\n",
        "random_state: Ensures reproducibility by setting a seed for the split."
      ],
      "metadata": {
        "id": "omshMqqUjgzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25. Explain data encoding?**\n",
        "\n",
        "Data encoding is the process of converting categorical data into numerical format so that machine learning algorithms can interpret it. Machine learning models require numerical input, and encoding transforms categories into numbers or binary vectors.\n",
        "\n",
        "**Common Types of Data Encoding:**\n",
        "1. **Label Encoding:** Converts each category into a unique integer.\n",
        "  * Example: [\"Red\", \"Green\", \"Blue\"] → [0, 1, 2]\n",
        "2. **One-Hot Encoding:** Converts each category into a binary vector. Each category is represented by a vector where only one value is 1 (indicating the category) and the rest are 0.\n",
        "  * Example: [\"Red\", \"Green\", \"Blue\"] → [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "  \n",
        "Data encoding helps models understand categorical variables and use them effectively in training."
      ],
      "metadata": {
        "id": "5xO_r-rRjwD5"
      }
    }
  ]
}